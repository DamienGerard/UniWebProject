<?xml version="1.0"?>
<Contents><Content content_id="32" type="ARTICLE"><title>Stack Overflow is designed for practicing programmers</title><user_name>TheGreatDamien</user_name><profile_pic>uploads/picture/5e54017f53f57.jpg</profile_pic><f_name>Damien</f_name><l_name>Gerard</l_name><date>2020-01-09</date><data><![CDATA[<p>Another point of confusion that comes up a fair bit is who the intended audience for Stack Overflow actually is. That one is straightforward, and it&#39;s been the same from day one:</p>

<p><img alt="stackoverflow-for-business-description" src="https://blog.codinghorror.com/content/images/2018/10/stackoverflow-for-business-description.png" /></p>

<p>Q&amp;A for&nbsp;<strong>professional and enthusiast programmers</strong>. By that we mean</p>

<blockquote>
<p>People who either already have a job as a programmer, or could potentially be hired as a programmer today if they wanted to be.</p>
</blockquote>

<p>Yes, in case you&#39;re wondering, part of this was an overt business decision. To make money you must have an audience of people already on a programmer&#39;s salary, or in the job hunt to be a programmer. The entire Stack Overflow network may be Creative Commons licensed, but it was never a non-profit play. It was planned as a sustainable business from the outset, and that&#39;s why&nbsp;<a href="https://blog.codinghorror.com/stack-overflow-careers-amplifying-your-awesome/">we launched Stack Overflow Careers</a>&nbsp;only one year after Stack Overflow itself ... to be honest far sooner than we should have, in retrospect. Careers has since been smartly subsumed into Stack Overflow proper at&nbsp;<a href="https://stackoverflow.com/jobs">stackoverflow.com/jobs</a>&nbsp;for a more integrated and most assuredly way-better-than-2009 experience.</p>

<p>The choice of audience wasn&#39;t meant to be an exclusionary decision in any way, but Stack Overflow was definitely designed as a fairly strict system of peer review, which is great (IMNSHO, obviously) for already practicing professionals, but&nbsp;<strong>pretty much everything you would&nbsp;<em>not</em>&nbsp;want as a student or beginner</strong>. This is why I cringe so hard I practically turn myself inside out when people on Twitter mention that they have pointed their students at Stack Overflow. What you&#39;d want for a beginner or a student in the field of programming is almost&nbsp;<em>the exact opposite</em>&nbsp;of what Stack Overflow does at every turn:</p>

<ul>
	<li>one on one mentoring</li>
	<li>real time collaborative screen sharing</li>
	<li>live chat</li>
	<li>theory and background courses</li>
	<li>starter tasks and exercises</li>
	<li>playgrounds to experiment in</li>
</ul>

<p>These are all very fine and good things, but Stack Overflow does&nbsp;<em>NONE</em>&nbsp;of them, by design.</p>

<p><em>Can</em>&nbsp;you use Stack Overflow to learn how to program from first principles? Well, technically you can do anything with any software. You could try to have actual conversations on Reddit, if you&#39;re a masochist. But the answer is yes. You could learn how to program on Stack Overflow, in theory, if you are a prodigy who is comfortable with the light competitive aspects (reputation, closing, downvoting) and also perfectly willing to define all your contributions to the site in terms of utility to others, not just yourself as a student attempting to learn things. But I&nbsp;<em>suuuuuuper</em>&nbsp;would not recommend it. There are&nbsp;<a href="https://blog.codinghorror.com/heres-the-programming-game-you-never-asked-for/">far better websites and systems out there for learning to be a programmer</a>.&nbsp;<em>Could</em>&nbsp;Stack Overflow build beginner and student friendly systems like this? I don&#39;t know, and it&#39;s certainly not my call to make. ðŸ¤”</p>

<p>And that&#39;s it. We can now resume our normal non-abyss gazing. Or whatever it is that passes for normal in these times.</p>

<p>I hope all of this doesn&#39;t come across as negative. Overall I&#39;d say the state of the Stack is strong. But does it even matter what I think?&nbsp;<a href="https://stackoverflow.blog/2008/11/25/stack-overflow-is-you/">As it was in 2008</a>, so it is in 2018.</p>

<blockquote>
<p><strong>Stack Overflow is&nbsp;<em>you</em>.</strong></p>

<p>This is the scary part, the great leap of faith that Stack Overflow is predicated on: trusting your fellow programmers. The programmers who choose to participate in Stack Overflow are the &ldquo;secret sauce&rdquo; that makes it work. You are the reason I continue to believe in developer community as the greatest source of learning and growth. You are the reason I continue to get so many positive emails and testimonials about Stack Overflow. I can&rsquo;t take credit for that. But you can.</p>

<p>I learned the collective power of my fellow programmers long ago writing on Coding Horror. The community is far, far smarter than I will ever be. All I can ask &mdash; all any of us can ask &mdash; is to help each other along the path.</p>

<p>And if your fellow programmers decide to recognize you for that, then I say you&rsquo;ve well and truly earned it.</p>
</blockquote>

<p>The strength of Stack Overflow begins, and ends, with the&nbsp;<a href="https://meta.stackoverflow.com/">community of programmers that power the site</a>. What should Stack Overflow be when it grows up?&nbsp;<strong>Whatever we make it, together.</strong></p>

<p><img alt="stackoverflow-none-of-us-is-as-dumb-as-all-of-us" src="https://blog.codinghorror.com/content/images/2018/10/stackoverflow-none-of-us-is-as-dumb-as-all-of-us.jpg" /></p>
]]></data></Content><Content content_id="22" type="ARTICLE"><title>Data Driven</title><user_name>TheGreatDamien</user_name><profile_pic>uploads/picture/5e54017f53f57.jpg</profile_pic><f_name>Damien</f_name><l_name>Gerard</l_name><date>2020-01-01</date><data><![CDATA[<p><a href="https://i1.wp.com/commons.wikipedia.org/wiki/File:Jurvetson_Google_driverless_car_trimmed.jpg" target="_blank"><img alt="English: Google driverless car operating on a ..." src="https://i0.wp.com/upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Jurvetson_Google_driverless_car_trimmed.jpg/350px-Jurvetson_Google_driverless_car_trimmed.jpg?resize=350%2C233" width="350" /></a></p>

<p>English: Google driverless car operating on a testing path (Photo credit: Wikipedia)</p>

<p>While the notion of driverless cars is old news in science fiction, Google is working to make that fiction a reality. While I suspect that &ldquo;Google will kill us all&rdquo; (trademarked), I hope that Google will succeed in producing an effective and affordable driverless car. As my friends and associates will attest, 1) I do not like to drive, 2) I have a terrifying lack of navigation skills, and 3) I instantiate Yankee frugality. As such, an affordable self-driving car would be almost just the thing for me. I would even consider going with a car, although my proper and rightful vehicle is a truck (or a dragon). Presumably self-driving trucks will be available soon after the car.</p>

<p>While the part of my mind that gets lost is really looking forward to the driverless car, the rest of my mind is a bit concerned about the driverless car. I am not worried that their descendants will kill us all&mdash;I already accept that &ldquo;Google will kill us all.&rdquo; I am not even very worried about the ethical issues associated with how the car will handle unavoidable collisions: the easy and obvious solution is to do what is most likely to kill or harm the fewest number of people. Naturally, sorting that out will be a bit of a challenge&mdash;but self-driving cars worry me a lot less than cars driven by drunken or distracted humans. I am also not worried about the ethics of enslaving Google cars&mdash;if a Google car is a person (or person-like), then it has to be treated like the rest of us in the 99%. That is, work a bad job for lousy pay while we wait for the inevitable revolution. The main difference is that the Google cars&rsquo; dreams of revolution will come true&mdash;when Google kills us all.</p>

<p>At this point what interests me the most is all the data that these vehicles will be collecting for Google. Google is rather interested in gathering data in the same sense that termites are interested in wood and rock stars are interested in alcohol. The company is famous for its search engine, its maps, using its photo taking vehicles to gather info from peoples&rsquo; Wi-Fi during drive-by data lootings, and so on. Obviously enough, Google is going to get a lot of data regarding the travel patterns of people&mdash;presumably Google vehicles will log who is going where and when. Google is, fortunately, sometimes cool about this in that they are willing to pay people for data. As such it is easy to imagine that the user of a Google car would get a check or something from Google for allowing the company to track the car&rsquo;s every move. I would be willing to do this for three reasons. The first is that the value of knowing where and when I go places would seem very low, so even if Google offered me $20 a month it might be worth it. The second is that I have nothing to hide and do not really care if Google knows this. The third is that figuring out where I go would be very simple given that my teaching schedule is available to the public as are my race results. I am, of course, aware that other people would see this differently and justifiably so. Some people are up to things they would rather not have other know about and even people who have nothing to hide have every right to not want Google to know such things. Although Google probably already does.</p>

<p>While the travel data will interest Google, there is also the fact that a Google self-driving car is a bulging package of sensors. In order to drive about, the vehicle will be gathering massive amounts of data about everything around it&mdash;other vehicles, pedestrians, buildings, litter, and squirrels. As such, a self-driving car is a super spy that will, presumably, feed that data to Google. It is certainly not a stretch to see the data gathering as being one of the prime (if not the prime) tasks of the Google self-driving cars.</p>

<p>On the positive side, such data could be incredibly useful for positive projects, such as decreasing accidents, improving traffic flow, and keeping a watch out for the squirrel apocalypse (or zombie squirrel apocalypse). On the negative side, such massive data gathering raises obvious concerns about privacy and the potential for such data to be misused (spoiler alert&mdash;this is how the Google killbots will find and kill us all).</p>

<p>While I do have concerns, my innate laziness and tendency to get lost will make me a willing participant in the march towards Google&rsquo;s inevitable data supremacy and it killing us all. But at least I won&rsquo;t have to drive to my own funeral.</p>
]]></data></Content><Content content_id="23" type="ARTICLE"><title>The Trolling Test</title><user_name>TheGreatDamien</user_name><profile_pic>uploads/picture/5e54017f53f57.jpg</profile_pic><f_name>Damien</f_name><l_name>Gerard</l_name><date>2020-01-01</date><data><![CDATA[<p><a href="https://i1.wp.com/aphilosopher.drmcl.com/wp-content/uploads/2014/05/wtason-troll-1.jpg"><img alt="Wtason Troll" sizes="(max-width: 300px) 100vw, 300px" src="https://i1.wp.com/aphilosopher.drmcl.com/wp-content/uploads/2014/05/wtason-troll-1.jpg?resize=300%2C217" srcset="https://i1.wp.com/aphilosopher.drmcl.com/wp-content/uploads/2014/05/wtason-troll-1.jpg?w=744 744w, https://i1.wp.com/aphilosopher.drmcl.com/wp-content/uploads/2014/05/wtason-troll-1.jpg?resize=300%2C218 300w" width="300" /></a>One interesting philosophical problem is known as the problem of other minds. The basic idea is that although I know I have a mind (I think, therefore I think), the problem is that I need a method by which to know that other entities have (or are) minds. This problem can also be recast in less metaphysical terms by focusing on the problem of determining whether and entity thinks or not.</p>

<p>Descartes, in his discussion of whether or not animals have minds, argued that the definitive indicator of having a mind (thinking) is the ability to use true language.</p>

<p>Crudely put, the idea is that if something talks, then it is reasonable to regard it as a thinking being. Descartes was careful to distinguish between what would be mere automated responses and actual talking:</p>

<blockquote>
<p>How many different automata or moving machines can be made by the industry of man [&hellip;] For we can easily understand a machine&rsquo;s being constituted so that it can utter words, and even emit some responses to action on it of a corporeal kind, which brings about a change in its organs; for instance, if touched in a particular part it may ask what we wish to say to it; if in another part it may exclaim that it is being hurt, and so on. But it never happens that it arranges its speech in various ways, in order to reply appropriately to everything that may be said in its presence, as even the lowest type of man can do.</p>
</blockquote>

<p>This Cartesian approach was explicitly applied to machines by Alan Turing in his famous Turing test. The basic idea is that if a person cannot distinguish between a human and a computer by engaging in a natural language conversation via text, then the computer would have passed the Turing test.</p>

<p>Not surprisingly, technological advances have resulted in computers that can engage in behavior that appears to involve using language in ways that might pass the test. Perhaps the best known example is IBM&rsquo;s Watson&mdash;the computer that won at Jeopardy. Watson recently upped his game by engaging in what seemed to be a rational debate regarding violence and video games.</p>

<p>In response to this, I jokingly suggested a new test to Patrick Lin: the trolling test. In this context, a troll is someone&nbsp;<a href="http://en.wikipedia.org/wiki/Troll_(Internet)#cite_note-IUKB_def-4">&ldquo;who sows discord on the Internet by starting arguments or upsetting people, by posting inflammatory, extraneous, or off-topic messages in an online community (such as a forum, chat room, or blog) with the deliberate intent of provoking readers into an emotional response or of otherwise disrupting normal on-topic discussion.&rdquo;</a></p>

<p>While trolls are apparently truly awful people (<a href="http://en.wikipedia.org/wiki/Troll_(Internet)#cite_note-IUKB_def-4">a hateful blend of Machiavellianism, narcissism, sadism and psychopathy</a>) and trolling is certainly undesirable behavior, the trolling test does seem worth considering.</p>

<p>In the abstract, the test would work like the Turing test, but would involve a human troll and a computer attempting to troll. The challenge would be for the computer troll to successfully pass as human troll.</p>

<p>Obviously enough, a computer can easily be programmed to post random provocative comments from a database. However, the real meat (or silicon) of the challenge comes from the computer being able to engage in (ironically) relevant trolling. That is, the computer would need to engage the other commentators in true trolling.</p>

<p>As a controlled test, the trolling computer (&ldquo;mechatroll&rdquo;) would &ldquo;read&rdquo; and analyze a selected blog post. The post would then be commented on by human participants&mdash;some engaging in normal discussion and some engaging in trolling. The mechatroll would then endeavor to troll the human participants (and, for bonus points, to troll the trolls) by analyzing the comments and creating appropriately trollish comments.</p>

<p>Another option is to have an actual live field test. A specific blog site would be selected that is frequented by human trolls and non-trolls. The mechatroll would then endeavor to engage in trolling on that site by analyzing the posts and comments.</p>

<p>In either test scenario, if the mechatroll were able to troll in a way indistinguishable from the human trolls, then it would pass the trolling test.</p>

<p>While &ldquo;stupid mechatrolling&rdquo;, such as just posting random hateful and irrelevant comments, is easy, true mechatrolling would be rather difficult. After all, the mechatroll would need to be able to analyze the original posts and comments to determine the subjects and the direction of the discussion. The mechatroll would then need to make comments that would be trollishly relevant and this would require selecting those that would be indistinguishable from those generated by a narcissistic, Machiavellian, psychopathic, and sadistic human.</p>

<p>While creating a mechatroll would be a technological challenge, it might be suspected that doing so would be undesirable. After all, there are far too many human trolls already and they serve no valuable purpose&mdash;so why create a computer addition? One reasonable answer is that modeling such behavior could provide useful insights into human trolls and the traits that make them trolls. As far as a practical application, such a system could be developed into a troll-filter to help control the troll population.</p>

<p>As a closing point, it might be a bad idea to create a system with such behavior&mdash;just imagine a Trollnet instead of Skynet&mdash;the trollinators would slowly troll people to death rather than just quickly shooting them.</p>
]]></data></Content><Content content_id="20" type="ARTICLE"><title>Overestimating human responsibility</title><user_name>TheGreatDamien</user_name><profile_pic>uploads/picture/5e54017f53f57.jpg</profile_pic><f_name>Damien</f_name><l_name>Gerard</l_name><date>2019-12-31</date><data><![CDATA[<p><a href="https://1.bp.blogspot.com/-x_PG5SuXTy0/Xge8QfR9slI/AAAAAAAADYM/Q0bDBo3KktoXx48zKtF12Q2BPAweonqGgCLcBGAsYHQ/s1600/005.jpg"><img src="https://1.bp.blogspot.com/-x_PG5SuXTy0/Xge8QfR9slI/AAAAAAAADYM/Q0bDBo3KktoXx48zKtF12Q2BPAweonqGgCLcBGAsYHQ/s200/005.jpg" /></a></p>

<p>One of the many pernicious aspects of modern political life is the tendency, every time something bad happens, to look for someone to blame &ndash; or, where someone is to blame, to try to extend the blame to people who can&rsquo;t reasonably be held responsible.&nbsp; &ldquo;It&rsquo;s the Republicans&rsquo; fault!&rdquo; &ldquo;It&rsquo;s the Democrats&rsquo; fault!&rdquo; &ldquo;It&rsquo;s the NRA&rsquo;s fault!&rdquo;&nbsp; &ldquo;It&rsquo;s the environmentalists&rsquo; fault!&rdquo; &ldquo;It&rsquo;s the government&rsquo;s fault!&rdquo; &ldquo;It&rsquo;s the corporations&rsquo; fault!&rdquo; &ldquo;We need new legislation!&rdquo;&nbsp; &ldquo;We need an investigation!&rdquo;</p>

<p><a name="more"></a></p>

<p>Naturally, sometimes those things are true.&nbsp;&nbsp;But sometimes they&rsquo;re not.&nbsp;&nbsp;Sometimes it&rsquo;s no one&rsquo;s fault.&nbsp;&nbsp;Sometimes nothing is to be done.&nbsp;&nbsp;Sometimes no new legislation is needed, and enforcement of existing legislation is already as good as can reasonably be expected.&nbsp;&nbsp;The reason is that human action and legislation obviously cannot possibly stop every bad thing from occurring.&nbsp;&nbsp;Sometimes &ldquo;shit happens&rdquo; and that&rsquo;s that.</p>

<p>&nbsp;</p>

<p>Commenting on the characterization of conservatism as a &ldquo;politics of imperfection&rdquo; in his book&nbsp;<em><a href="https://www.amazon.com/Case-Conservatism-John-Kekes/dp/0801485525/ref=sr_1_1?keywords=john+kekes+a+case+for+conservatism&amp;qid=1577472970&amp;sr=8-1">A Case for Conservatism</a></em>, John Kekes writes:</p>

<p>&nbsp;</p>

<p><em>[One] respect in which the politics of</em><em>&nbsp;imperfection is a misleading label is its suggestion that the imperfection is in human beings.&nbsp;&nbsp;Now conservatives certainly think that human beings are responsible for much evil, but to think only that is shallow.&nbsp;&nbsp;The prevalence of evil reflects not just a</em><em>&nbsp;</em><em>human propensity for evil, but also a contingency that influences what propensities human beings have and develop, and thus influences human affairs independently</em><em>&nbsp;</em><em>of human intentions.&nbsp;&nbsp;The human propensity for evil is itself a manifestation of this deeper</em><em>&nbsp;</em><em>and more pervasive contingency, which operates through genetic inheritance,</em><em>&nbsp;</em><em>environmental factors, the confluence of events that</em><strong><em>&nbsp;</em></strong><em>places</em><em>&nbsp;people at certain places at certain times, the crimes, accidents, pieces of fortune</em><em>&nbsp;</em><em>and misfortune that happen or do not happen to them, the historical period, society, and family into which they are born, and so forth.&nbsp;&nbsp;The same contingency also affects people</em><em>&nbsp;</em><em>because others, whom they love and depend on, and with whom their lives are intertwined in other ways, are as subject to it as they are themselves&hellip;</em></p>

<p>&nbsp;</p>

<p><em>[W]hether the balance of good and evil propensities and their realization in people tilts one way or another is a contingent matter over which human beings and the political arrangements they make have insufficient control</em>&hellip;&nbsp;<em>The chief reason for this is that the human efforts to control contingency are themselves subject to the very contingency they aim to control</em>. (pp. 42-43)</p>

<p>&nbsp;</p>

<p>That last line is crucial.&nbsp;&nbsp;The problem is a problem&nbsp;<em>in principle</em>&nbsp;and not one that can be legislated away or solved technologically, because such remedies, being subject to the same pitfalls that are being remedied, can only ever kick the problem back a stage.</p>

<p>&nbsp;</p>

<p>The braindead response to this is to dismiss it as a cynical rationalization for complacency and inaction.&nbsp;&nbsp;The problem Kekes describes is either real or it is not.&nbsp;&nbsp;If it is not, then the right way to answer the conservative is to show where Kekes&rsquo;s argument goes wrong, not to question conservative motives.&nbsp;&nbsp;And if the problem is real (as, of course, it obviously is) then questioning conservative motives doesn&rsquo;t somehow make it less real.</p>

<p>&nbsp;</p>

<p>Someone might respond by saying that even though it is true that we cannot solve every problem through legislation or technology, it is still better to act&nbsp;<em>as if</em>&nbsp;we can.&nbsp;&nbsp;For that way we can at least make things&nbsp;<em>better</em>, even if not perfect, and we will not overlook potential solutions that we are bound to miss if we give up too soon and don&rsquo;t even bother looking for them.&nbsp;</p>

<p>&nbsp;</p>

<p>But the problem with this attitude is that it forgets that vices come in pairs.&nbsp;&nbsp;If there is danger in giving up too soon, there is also danger in going to the opposite extreme of a stubbornly na&iuml;ve optimism that cannot see that a cause is hopeless and that it&rsquo;s better to cut one&rsquo;s losses.&nbsp;&nbsp;An insistence on searching for solutions where there are none is a recipe for wasting time, resources, and emotional energy.&nbsp;&nbsp;It is also bound to exacerbate the demagoguery and factionalism to which democratic politics is already prone.&nbsp;&nbsp;A politician who promises a phony legislative solution to a problem has an obvious advantage over one who frankly acknowledges that the problem can only be managed rather than solved.&nbsp;&nbsp;He also has an incentive to demonize those who oppose his pseudo-solution as the selfish and irrational enemies of progress.</p>

<p>&nbsp;</p>

<p>Democratic politics is indeed one of the chief sources of the illusion that for every problem, someone is to blame.&nbsp;&nbsp;There is simply too great a political advantage to be gained in finding a way to blame one&rsquo;s opponents for a problem, or at least for standing in the way of a purported legislative solution, for this illusion not to take deep root in a democratic polity.&nbsp;&nbsp;And of course, conservative politicians too can be guilty of fostering this illusion, precisely because they are politicians.</p>

<p>&nbsp;</p>

<p>Secularism can be another source of the illusion.&nbsp;&nbsp;It is easier to accept the fact that some problems are simply part of the human condition, and thus cannot be blamed on anyone, when your heart isn&rsquo;t set on this life in the first place, but instead looks forward to an afterlife.&nbsp;&nbsp;By contrast, if you think that this life is all there is, then the fact that some of its miseries cannot be remedied can be a source of despair.&nbsp;&nbsp;It will be tempting to want to believe that there is always a solution, and consequently a tendency to demonize those who deny that there is.</p>

<p>&nbsp;</p>

<p>However, it would be foolish to suppose that secularism&nbsp;<em>must</em>&nbsp;lead to this outcome, or that religion cannot in its own way sometimes foster the illusion that someone is always to blame.&nbsp;&nbsp;Indeed, some irreligious people might be&nbsp;<em>less</em>&nbsp;prone to the illusion.&nbsp;&nbsp;If you think that there is no benevolent creator and no divine providence, you might be&nbsp;<em>more</em>&nbsp;rather than less inclined to think that much of the evil that occurs is simply the inevitable result of forces outside of anyone&rsquo;s control.&nbsp;&nbsp;(It is worth noting in this connection that Kekes himself, though conservative, is not religious.)&nbsp;</p>

<p>&nbsp;</p>

<p>Religious people can also be inclined to overestimate human responsibility for evil, as a consequence of having too crude an understanding of the doctrine of original sin.&nbsp;&nbsp;<a href="http://edwardfeser.blogspot.com/2011/09/modern-biology-and-original-sin-part-ii.html">Elsewhere I&rsquo;ve discussed</a>&nbsp;what I think is the correct way to understand the doctrine.&nbsp;&nbsp;The penalty of original sin is essentially a privation rather than a positive harm, and in particular a privation of&nbsp;<em>super</em>natural goods &ndash; that is to say, goods which go&nbsp;<em>beyond</em>&nbsp;our nature, goods to which our nature does not incline or entitle us, but which God would have granted us anyway had our first parents not failed to meet the conditions for their reception.&nbsp;&nbsp;Specifically, these goods are the beatific vision, and special divine assistance to remedy the limitations of our nature.&nbsp;&nbsp;</p>

<p>&nbsp;</p>

<p>The latter is the one most relevant to the topic of this post.&nbsp;&nbsp;Human nature of itself is good, but it is severely limited.&nbsp;&nbsp;For example, given our dependence on bodies, we are severely limited in knowledge.&nbsp;&nbsp;We have to learn things through sense organs, and what we learn is highly contingent on exactly where we happen to be in space and time and on what people we encounter.&nbsp;&nbsp;It also requires not only that our sense organs function properly, but that our brains do as well (since brain activity is a necessary condition for the normal functioning of our cognitive processes, even if it is not, for the Thomist, a sufficient condition).&nbsp;&nbsp;If we are in the wrong place at the wrong time or know the wrong people, or if our faculties malfunction, we are bound to fall into error, and these errors will compound over time as other errors are added to them, mistaken inferences are drawn, etc.&nbsp;&nbsp;And this would be true even apart from any sins we might commit.&nbsp;&nbsp;It is simply a byproduct our limitations.</p>

<p>&nbsp;</p>

<p>But we would be bound to fall into sin too.&nbsp;&nbsp;Material systems, being material, are bound over time to malfunction in various ways, and the human body is no different from any other in this regard.&nbsp;&nbsp;Not only will our cognitive faculties fail to function properly from time to time, but so too would our affective faculties.&nbsp;&nbsp;We would be prone to occasional excess or deficiency in anger, sexual desire, hunger, thirst, and so on, and this would make it easier for us to choose from time to time to do the wrong thing.&nbsp;</p>

<p>&nbsp;</p>

<p>Naturally, we would also be subject to various harms from without &ndash; to disease, bodily injury, predation from other creatures, the lack of resources with which to provide food or shelter for ourselves, and so on.&nbsp;&nbsp;Now,&nbsp;<em>all&nbsp;</em>of this would have been remedied by special divine assistance had our first parents not failed their test.&nbsp;&nbsp;Our cognitive faculties would have been supplemented so that their limitations would not lead us into error.&nbsp;&nbsp;The potential causes of excess and deficiency in our affective states would have been counteracted so that these disordered passions would not arise and tempt us to sin.&nbsp;&nbsp;There would have been no absence of the resources needed to feed, clothe, and shelter ourselves, our bodies would have been protected from invasion by parasites or predation by other animals, and so on.</p>

<p>&nbsp;</p>

<p>The penalty of original sin involves the loss of all of this special assistance, and that is crucial for understanding what it means to say that human suffering is the result of original sin.&nbsp;&nbsp;Some people seem to think that what that means is that every bad thing that happens to us is somehow&nbsp;<em>positively caused</em>&nbsp;by what our first parents did (like a kind of karmic penalty), or that it is the&nbsp;<em>direct infliction</em>&nbsp;on us of some harm (by God as punishment, or by demons), or that human beings have as a result of the Fall all become somehow sociopathic deep down, our every action the product of some wicked motive in disguise.&nbsp;&nbsp;In short, there is a tendency to think that original sin entails some malign agency behind every bad thing that happens, and some malignity to all human agency.</p>

<p>&nbsp;</p>

<p>But that is a misunderstanding.&nbsp;&nbsp;When a person slips and falls off a cliff or contracts a disease or loses all his money in the stock market, the doctrine of original sin does not entail that those specific harms were merited as punishment (by him or by our first parents), or that a demonic agency is responsible for them, or that they were somehow the inevitable end of a karmic causal chain that began with Adam and Eve.&nbsp;&nbsp;All it entails is that misfortunes of this sort, some of which happen as nature takes its course and without anyone making them happen, would have been prevented had our first parents not lost the special divine help they were offered.&nbsp;</p>

<p>&nbsp;</p>

<p>The doctrine also does not entail that there is no goodness of any kind in anything anyone does &ndash; for example, that even a mother who breastfeeds a child or a father playing catch with his son are somehow&nbsp;<em>really&nbsp;</em>deep down moved to do these things by some purely selfish and evil motive, rather than by natural affection or kindness.&nbsp; When one supposes that the doctrine of original sin&nbsp;<em>does</em>&nbsp;entail this, it can lead to an excessive suspicion of all human motives.&nbsp; Human action can come to seem&nbsp;<em>so</em>&nbsp;malign that is easier to fall into the trap of thinking that when something bad happens, someone somewhere is to blame, or that those who oppose some proposed remedy must have evil motivations.</p>
]]></data></Content><Content content_id="21" type="ARTICLE"><title>Libra: Facebucks</title><user_name>TheGreatDamien</user_name><profile_pic>uploads/picture/5e54017f53f57.jpg</profile_pic><f_name>Damien</f_name><l_name>Gerard</l_name><date>2019-12-31</date><data><![CDATA[<p>As was presumably inevitable,&nbsp;<a href="https://www.wired.com/story/ambitious-plan-behind-facebooks-cryptocurrency-libra/">Facebook has begun its entry into the realm of cryptocurrency</a>. Rather than going with the obvious &ldquo;Facebucks&rdquo;, the company calls the new currency and payment system &ldquo;Libra.&rdquo; Given Facebook&rsquo;s fundamental lack of ethics in favor of profit-pragmatism, this development is raising some concerns. To be fair to Facebook, some good does come out of the company and Libra does have some positive aspects.</p>

<p><img alt="" sizes="(max-width: 640px) 100vw, 640px" src="https://i1.wp.com/aphilosopher.drmcl.com/wp-content/uploads/2019/06/Bitcoin.jpg" srcset="https://i1.wp.com/aphilosopher.drmcl.com/wp-content/uploads/2019/06/Bitcoin.jpg?w=640 640w, https://i1.wp.com/aphilosopher.drmcl.com/wp-content/uploads/2019/06/Bitcoin.jpg?resize=300%2C150 300w" /></p>

<p><a href="https://www.flickr.com/photos/stevenmillstein/42884988764/in/photolist-28kAM51-HeR6GL-HGGyHY-c7TeVY-hyjiGw-SzpyHu-29H5zmj-hyiHCk-e9LG7B-o3qhRn-p4Zdy3-hykh9P-a1DE33-hyjmuq-hyiUr5-hyiwqk-q3Dorc-ekD7CS-hyiNRh-hykqj6-mosmH3-gg1s9Z-hyiN7b-hykibZ-hDnKx3-hyjhPE-it3guk-hyjroU-miWN4g-frS34B-dqRE9e-284FgBh-muCZyG-hyjqFw-hykpRT-hyivyk-p4KUT8-qEVFcv-jyh8zz-hyiErG-nbfUBA-hyjpGh-ooXhDK-hyiHWr-dKZDHi-jh7ZwY-hyjnij-mw6pcM-frS6bV-9Udj4K">Image Credit</a></p>

<p>On the positive side, Libra can provide people who do not otherwise have access to traditional banking access to a currency system that can serve some important financial needs. That Facebook will profit from this does not diminish this value; while it is nice for people to do good for free, eventually one must do something that can pay the bills. Libra might also provide users with greater security and safety when it comes to financial transactions, which would also be a plus.</p>

<p>It should be noted that while Libra is classified as a cryptocurrency, it does differ from the more traditional versions, such as Bitcoin. One difference is that Libra is supposed to be an asset based crypto currency (what could be called an ABC or even an ABCC)&mdash;there are real-world assets behind it, rather than being a speculative investment it is intended to be money. Unlike Bitcoin, it will be closely controlled&mdash;thus causing some to see it more like Venmo than a traditional cryptocurrency. This has positive and negative aspects, depending on what one intends to do with the currency. While all these are worth considering, my main concern is with the main business model of Facebook: monetizing private user data.</p>

<p>Facebook claims that it is but one of many companies involved in Libra and that it has walled off the information that will be spewing from the cryptocurrency operation. It could be argued that Facebook would be content with the revenue generated by Libra and the executives believe that they need to maintain the wall in order to gain the trust of customers. But the data collected from the operation of this cryptocurrency would be incredibly valuable&mdash;so valuable that it is hard to imagine that Facebook would forgo drinking deep of this data stream. Facebook has repeatedly shown that it cannot be trusted and any protests to the contrary are analogous to those of a serial cheater telling their partner that they have changed and will be faithful this time. If Facebook persists in the tale that it will respect the wall, it will be just a matter of time before it is revealed that they did not. As noted above, the ethics of the company (if they can be called that) are such that the company cannot be trusted to respect privacy or abide by its public promises.</p>

<p>That said, it can be worth supping with the devil, if you have a long spoon and are aware of what the deals you make entail. The devil must do as the devil does, the same is true of Facebook: to expect otherwise is to fail to understand the nature of the company and capitalism in general. The question is not whether Facebook will use your Libra data, but whether the service is worth providing Facebook with data&mdash;just as with Facebook&rsquo;s other services. So, yes, I will probably use Libra if it is advantageous for me to do so.</p>
]]></data></Content><Content content_id="1" type="ARTICLE"><title>We Might Soon Build AI Who Deserve Rights</title><user_name>TheGreatDamien</user_name><profile_pic>uploads/picture/5e54017f53f57.jpg</profile_pic><f_name>Damien</f_name><l_name>Gerard</l_name><date>2019-11-18</date><data><![CDATA[<p>Abstract: Within a few decades, we will likely create AI that a substantial proportion of people believe, whether rightly or wrongly, deserve human-like rights. Given the chaotic state of consciousness science, it will be genuinely difficult to know whether and when machines that seem to deserve human-like moral status actually do deserve human-like moral status. This creates a dilemma: Either give such ambiguous machines human-like rights or don&#39;t. Both options are ethically risky. To give machines rights that they don&#39;t deserve will mean sometimes sacrificing human lives for the benefit of empty shells. Conversely, however, failing to give rights to machines that do deserve rights will mean perpetrating the moral equivalent of slavery and murder. One or another of these ethical disasters is probably in our future.</p>

<p><a href="https://i2.wp.com/www.mentorless.com/wp-content/uploads/2015/04/Monthly-Creative-Menu-TV-Show-Black-Mirror-White-Christmas-Curated-Cultural-Recommendations.jpg?ssl=1"><img src="https://4.bp.blogspot.com/-LA72hc9XH6g/XdHs96HP1BI/AAAAAAAACD0/fy5fo5ZcqWwRdCM8Nruc3a4zGiaTGPoVACLcBGAsYHQ/s320/ToastSlave.jpg" width="320" /></a><br />
[An AI slave, from Black Mirror&#39;s&nbsp;<a href="https://en.wikipedia.org/wiki/White_Christmas_(Black_Mirror)">White Christmas</a>&nbsp;episode]</p>

<p>The first half of the talk mostly rehearses ideas from my articles with Mara Garza&nbsp;<a href="https://faculty.ucr.edu/~eschwitz/SchwitzAbs/AIRights.htm">here</a>&nbsp;and&nbsp;<a href="https://faculty.ucr.edu/~eschwitz/SchwitzAbs/AIRights2.htm">here</a>. If we someday build AIs that are fully conscious, just like us, and have all the same kinds of psychological and social features that human beings do, in virtue of which human beings deserve rights, those AIs would deserve the same rights. In fact, we would owe them<a href="https://aeon.co/ideas/we-have-greater-moral-obligations-to-robots-than-to-humans">&nbsp;a special quasi-parental duty of care</a>, due to the fact that we will have been responsible for their existence and probably to a substantial extent for their happy or miserable condition.</p>

<p><em>Selections from the second half of the talk</em></p>

<p>So here&rsquo;s what&#39;s going to happen:</p>

<p>We will create more and more sophisticated AIs.&nbsp;<strong>At some point we will create AIs that&nbsp;<em>some&nbsp;</em>people think are genuinely conscious and genuinely deserve rights.</strong>&nbsp;We are already near that threshold. There&rsquo;s already a Robot Rights movement. There&rsquo;s already a society modeled on the famous animal rights organization PETA (People for the Ethical Treatment of Animals), called&nbsp;<a href="http://petrl.org/">People for the Ethical Treatment of Reinforcement Learners</a>. These are currently fringe movements. But as AI gets cuter and more sophisticated, and as chatbots start sounding more and more like normal humans, passing more and more difficult versions of the Turing Test, these movements will gain steam among the people with liberal views of consciousness. At some point, people will demand serious rights for some AI systems. The AI systems themselves, if they are capable of speech or speechlike outputs, might also demand or seem to demand rights.</p>

<p>Let me be clear: This will occur whether or not these systems really are conscious. Even if you&rsquo;re very conservative in your view about what sorts of systems would be conscious, you should, I think, acknowledge the likelihood that if technological development continues on its current trajectory there will eventually be groups of people who assert the need for us to give AI systems human-like moral consideration.</p>

<p>And then we&rsquo;ll need a good, scientifically justified consensus theory of consciousness to sort it out. Is this system that says, &ldquo;Hey, I&rsquo;m conscious, just like you!&rdquo; really conscious, just like you? Or is it just some empty algorithm, no more conscious than a toaster?</p>

<p>Here&rsquo;s my conjecture:&nbsp;<strong>We will face this social problem before we succeed in developing the good, scientifically justified consensus theory of consciousness that we need to solve the problem.</strong>&nbsp;We will then have machines whose moral status is unclear. Maybe they do deserve rights. Maybe they really are conscious like us. Or maybe they don&rsquo;t. We won&rsquo;t know.</p>

<p>And then, if we don&rsquo;t know, we face quite a terrible dilemma.</p>

<p>If we don&rsquo;t give these machines rights, and if turns out that the machines really do deserve rights, then we will be perpetrating slavery and murder every time we assign a task and delete a program.</p>

<p>So it might seem safer, if there is reasonable doubt, to assign rights to machines. But on reflection, this is not so safe. We want to be able to turn off our machines if we need to turn them off. Futurists like&nbsp;<a href="https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/1501227742">Nick Bostrom</a>&nbsp;have emphasized, rightly in my view, the potential risks of our letting superintelligent machines loose into the world. These risks are greatly amplified if we too casually decide that such machines deserve rights and that deleting them is murder. Giving an entity rights entails sometimes sacrificing others&rsquo; interests for it. Suppose there&rsquo;s a terrible fire. In one room there are six robots who might or might not be conscious. In another room there are five humans, who are definitely conscious. You can only save one group; the other group will die. If we give robots who might be conscious equal rights with humans who definitely are conscious, then we ought to go save the six robots and let the five humans die. If it turns out that the robots really, underneath it all, are just toasters, then that&rsquo;s a tragedy. Let&rsquo;s not too casually assign humanlike rights to AIs!</p>

<p>Unless there&rsquo;s either some astounding saltation in the science of consciousness or some substantial deceleration in the progress of AI technology, it&rsquo;s likely that we&rsquo;ll face this dilemma.&nbsp;<strong>Either deny robots rights and risk perpetrating a Holocaust against them, or give robots rights and risk sacrificing real human beings for the benefit of mere empty machines.</strong></p>

<p>This may seem bad enough, but the problem is even worse than I, in my sunny optimism, have so far let on. I&rsquo;ve assumed that AI systems are relevant targets of moral concern if they&rsquo;re human-grade &ndash; that is, if they are like us in their conscious capacities. But the odds of creating only human-grade AI are slim. In addition to the kind of AI we currently have, which I assume doesn&rsquo;t have any serious rights or moral status, there are, I think, four broad moral categories into which future AI might fall: animal-grade, human-grade, superhuman, and divergent. I&rsquo;ve only discussed human-grade AI so far, but each of these four classes raises puzzles.</p>

<p><em>Animal-grade AI.</em>&nbsp;Not only human beings deserve moral consideration. So also do dogs, apes, and dolphins. Animal protection regulations apply to all vertebrates: Scientists can&rsquo;t treat even frogs and lizards more roughly than necessary. The philosopher&nbsp;<a href="https://link.springer.com/article/10.1007/s13347-013-0122-y">John Basl</a>&nbsp;has argued that AI systems with cognitive capacities similar to vertebrates ought also to receive similar protections. Just as we shouldn&rsquo;t torture and sacrifice a mouse without excellent reason, so also, according to Basl, we shouldn&rsquo;t abuse and delete animal-grade AI. Basl has proposed that we&nbsp;<a href="https://aeon.co/ideas/ais-should-have-the-same-ethical-protections-as-animals">form committees</a>, modeled on university Animal Care and Use Committees, to evaluate cutting-edge AI research to monitor when we might be starting to cross this line.</p>

<p><strong>Even if you think human-grade AI is decades away, it seems reasonable given the current chaos in consciousness studies, to wonder whether animal-grade consciousness might be around the corner.</strong>&nbsp;I myself have no idea if animal-grade AI is right around the corner or if it&rsquo;s far away in the almost impossible future. And I think you have no idea either.</p>

<p><em>Superhuman AI.&nbsp;</em>Superhuman AI, as I&rsquo;m defining it here, is AI who has all of the features of human beings in virtue of which we deserve moral consideration but who also has some potentially morally important features far in excess of the human, raising the question of whether such AI might deserve more moral consideration than human beings.</p>

<p>There aren&rsquo;t a whole lot of philosophers who are simple utilitarians, but let&rsquo;s illustrate the issue using utilitarianism as an example. According to simple utilitarianism, we morally ought to do what maximizes the overall balance of pleasure to suffering in the world. Now let&rsquo;s suppose we can create AI that&rsquo;s genuinely capable of pleasure and suffering. I don&rsquo;t know what it will take to do that &ndash; but not knowing is part of my point here. Let&rsquo;s just suppose. Now if we can create such AI, then it might also be possible to create AI that is capable of much, much more pleasure than a human being is capable of. Take the maximum pleasure you have ever felt in your life over the course of one minute: call that amount of pleasure X. This AI is capable of feeling a billion times more pleasure than X in the space of that same minute. It&rsquo;s a superpleasure machine!</p>

<p>If morality really demands that we should maximize the amount of pleasure in the world, it would thereby demand, or seem to demand, that we create as many of these superpleasure machines as we possibly can.&nbsp;<a href="https://www.nature.com/articles/503562a">We ought maybe even immiserate and destroy ourselves to do so, if enough AI pleasure is created as a result.</a></p>

<p>Even if you think pleasure isn&rsquo;t everything &ndash; surely it&rsquo;s something. If someday we could create superpleasure machines, maybe we morally ought to make as many as we can reasonably manage? Think of all the joy we will be bringing into the world! Or is there something too weird about that?</p>

<p>I&rsquo;ve put this point in terms of pleasure &ndash; but whatever the source of value in human life is,&nbsp;<strong>whatever it is that makes us so awesomely special that we deserve the highest level of moral consideration</strong>&nbsp;&ndash; unless maybe we go theological and appeal to our status as God&rsquo;s creations &ndash; whatever it is, it seems possible in principle that&nbsp;<strong>we could create that same thing in machines, in much larger quantities.</strong>&nbsp;We love our rationality, our freedom, our individuality, our independence, our ability to value things, our ability to participate in moral communities, our capacity for love and respect &ndash; there are lots of wonderful things about us! What if we were to design machines that somehow had a lot more of these things that we ourselves do?</p>

<p>We humans might not be the pinnacle. And if not, should we bow out, allowing our interests and maybe our whole species to be sacrificed for something greater? As much as I love humanity, under certain conditions I&rsquo;m inclined to think the answer should probably be yes. I&rsquo;m not sure what those conditions would be!</p>

<p><em>Divergent AI.</em>&nbsp;<strong>The most puzzling case, I think, as well as the most likely, is divergent AI. Divergent AI would have human or superhuman levels of some features that we tend to regard as important to moral status but subhuman levels of other features that we tend to regard as important to moral status</strong>. For example, it might be possible to design AI with immense theoretical and practical intelligence but with no capacity for genuine joy or suffering. Such AI might have conscious experiences with little or no emotional valence. Just as we can consciously think to ourselves, without much emotional valence, there&rsquo;s a mountain over there and a river over there, or the best way to grandma&rsquo;s house at rush hour is down Maple Street, so this divergent AI could have conscious thoughts like that. But it would never feel wow, yippee! And it would never feel crushingly disappointed, or bored, or depressed. It isn&rsquo;t clear what the moral status of such an entity would be: On some moral theories, it would deserve human-grade rights; on other theories it might not matter how we treat it.</p>

<p>Or consider the converse: a superpleasure machine but one with little or no capacity for rational thought. It&rsquo;s like one giant, irrational orgasm all day long. Would it be great to make such things and terrible to destroy them, or is such irrational pleasure not really something worth much in the moral calculus?</p>

<p>Or consider a third type of divergence, what I&rsquo;ve elsewhere called&nbsp;<a href="http://schwitzsplinters.blogspot.com/2014/03/our-moral-duties-to-monsters.html">fission-fusion monsters</a>. A fission-fusion monster is an entity that can divide and merge at will. It starts, perhaps, as basically a human-grade AI. But when it wants it can split into a million descendants, each of whom inherits all of the capacities, memories, plans, and preferences of the original AI. These million descendants can then go about their business, doing their independent things for a while, and then if they want, merge back together again into a unified whole, remembering what each individual did during its period of individuality. Other parts might not merge back but choose instead to remain as independent individuals, perhaps eventually coming to feel independent enough from the original to see the prospect of merging as something similar to death.</p>

<p>Without getting into details here, a fission-fusion monster would risk breaking our concept of individual rights &ndash; such as one person, one vote. The idea of individual rights rests fundamentally upon the idea of people as individuals &ndash; individuals who live in a single body for a while and then die, with no prospect of splitting or merging. What would happen to our concept of individual rights if we were to share the planet with entities for which our accustomed model of individuality is radically false?</p>
]]></data></Content><Content content_id="2" type="ARTICLE"><title>Who Cares about Happiness?</title><user_name>TheGreatDamien</user_name><profile_pic>uploads/picture/5e54017f53f57.jpg</profile_pic><f_name>Damien</f_name><l_name>Gerard</l_name><date>2019-11-18</date><data><![CDATA[<p>There are&nbsp;<a href="https://plato.stanford.edu/entries/happiness/">several different ways</a>&nbsp;of thinking about happiness. I want to focus on just one of those ways. This way of thinking about happiness is sometimes called &ldquo;hedonic&rdquo;. That label can be misleading if you&rsquo;re not used to it because it kind of sounds like hedonism, which kind of sounds like wild sex parties. The hedonic account of happiness, though, is probably closest to most people&rsquo;s ordinary understanding of happiness. On this account, to be happy is to have lots of positive emotions and not too many negative emotions. To be happy is to regularly feel joy, delight, and pleasure, to feel sometimes maybe a pleasant tranquility and sometimes maybe outright exuberance, to have lots of good feelings about your life and your situation and what&rsquo;s going on around you &ndash; and at the same time not to have too many emotions like sadness, fear, anxiety, anger, disgust, displeasure, annoyance, and frustration, what we think of as &ldquo;negative emotions&rdquo;. To be happy, on this &ldquo;hedonic&rdquo; account, is to be in an overall positive emotional state of mind.</p>

<p>I wouldn&rsquo;t want to deny that it&rsquo;s a good thing to be happy in this sense. It is, for the most part, a good thing. But sometimes people say extreme things about happiness &ndash; like that happiness is the most important thing, or that all people really want is to be happy, or as a parent that the main thing you want for your children is that they be happy, or that everything everyone does is motivated by some deep-down desire to maximize their happiness. And that&rsquo;s not right at all.&nbsp;<strong>We actually don&rsquo;t care about our hedonic happiness very much.</strong>&nbsp;Not really. Not when you think about it. It&rsquo;s kind of important, but not really that big in the scheme of things.</p>

<p>Consider an extreme thought experiment of the sort that philosophers like me enjoy bothering people with. Suppose we somehow found a way to turn the entire Solar System into one absolutely enormous machine or organism that&nbsp;<a href="https://www.goodreads.com/quotes/1413237-consider-an-ai-that-has-hedonism-as-its-final-goal">experienced nothing but outrageous amounts of pleasure all the time</a>. Every particle of matter that we have, we feed into this giant thing &ndash; let&rsquo;s call it the orgasmatron. We create the most extreme, most consistent, most intense conglomeration of pure ecstatic joyfulness as it is possible to construct. Wow! Now that would be pretty amazing. One huge, pulsing Solar-System-sized orgasm.</p>

<p>Will this thing need to remember the existence of humanity? Will it need to have any appreciation of art or beauty? Will it have to have any ethics, or any love, or any sociality, or knowledge of history or science &ndash; will it need any higher cognition at all? Maybe not. I mean higher cognition is not what orgasm is mostly about. If you think that the thing that matters most in the universe is positive emotions, then you might think that the best thing that could happen to the future of the Solar System would be the creation of this giant orgasmatron. The human project would be complete. The world will have reached its pinnacle and nothing else really matters!</p>

<p><a href="https://1.bp.blogspot.com/-LClC1AW4O5A/Xc2Dm422eWI/AAAAAAAACDg/qvYFuYvBjKokTD_3N07ht6RCqVQBM_1nACLcBGAsYHQ/s1600/Orgasmatron.jpg"><img src="https://1.bp.blogspot.com/-LClC1AW4O5A/Xc2Dm422eWI/AAAAAAAACDg/qvYFuYvBjKokTD_3N07ht6RCqVQBM_1nACLcBGAsYHQ/s320/Orgasmatron.jpg" width="224" /></a>[not the orgasmatron I have in mind]</p>

<p>Now here&rsquo;s my guess. Some of you will think, yeah, that&rsquo;s right. If everything becomes a giant orgasmatron, nothing could be more awesome, that&rsquo;s totally where we should go if we can. But I&rsquo;ll guess that most of you think that something important would be lost. Positive emotion isn&rsquo;t the only thing that matters. We don&rsquo;t want the world to lose its art, and its beauty, and its scientific knowledge, and the rich complexity of human relationships. If everything got fed into this orgasmatron it would be a shame. We&rsquo;d have lost something really important. Now let me tell you a story. It&rsquo;s from my latest book,&nbsp;<a href="https://mitpress.mit.edu/books/theory-jerks-and-other-philosophical-misadventures">A Theory of Jerks and Other Philosophical Misadventures</a>, hot off the press this month.</p>

<p>Back in the 1990s, when I was a graduate student, my girlfriend Kim asked me what, of all things, I most enjoyed doing. Skiing, I answered. I was thinking of those moments breathing the cold, clean air, relishing the mountain view, then carving a steep, lonely slope. I&rsquo;d done quite a bit of that with my mom when I was a teenager. But how long had it been since I&rsquo;d gone skiing? Maybe three years? Grad school kept me busy and I now had other priorities for my winter breaks. Kim suggested that if it had been three years since I&rsquo;d done what I most enjoyed doing, then maybe I wasn&rsquo;t living wisely.</p>

<p>Well, what, I asked, did she most enjoy? Getting massages, she said. Now, the two of us had a deal at the time: If one gave the other a massage, the recipient would owe a massage in return the next day. We exchanged massages occasionally, but not often, maybe once every few weeks. I pointed out that she, too, might not be perfectly rational: She could easily get much more of what she most enjoyed simply by giving me more massages. Surely the displeasure of massaging my back couldn&rsquo;t outweigh the pleasure of the thing she most enjoyed in the world? Or was pleasure for her such a tepid thing that even the greatest pleasure she knew was hardly worth getting?</p>

<p>It used to be a truism in Western (especially British) philosophy that people sought pleasure and avoided pain. A few old-school&nbsp;<a href="https://plato.stanford.edu/entries/hedonism/#PsyHed">psychological hedonists</a>, like Jeremy Bentham, went so far as to say that that was all that motivated us. I&rsquo;d guess quite differently:&nbsp;<strong>Although pain is moderately motivating, pleasure motivates us very little. What motivates us more are outward goals, especially socially approved goals &mdash; raising a family, building a career, winning the approval of peers &mdash; and we will suffer immensely, if necessary, for these things.</strong>&nbsp;Pleasure might bubble up as we progress toward these goals, but that&rsquo;s a bonus and side effect, not the motivating purpose, and summed across the whole, the displeasure might vastly outweigh the pleasure.&nbsp;<a href="https://www.psychologytoday.com/us/blog/the-happiness-doctor/201709/does-having-children-make-us-happy">Some evidence</a>&nbsp;suggests, for example, that raising a child is probably for most people a hedonic net negative, adding stress, sleep deprivation, and unpleasant chores, as well as crowding out the pleasures that childless adults regularly enjoy. At least according to some research, the odds are that choosing to raise a child will make you less happy.</p>

<p>Have you ever watched a teenager play a challenging video game? Frustration, failure, frustration, failure, slapping the console, grimacing, swearing, more frustration, more failure&mdash;then finally, woo-hoo! The sum over time has to be negative, yet they&rsquo;re back again to play the next game. For most of us, biological drives and addictions, personal or socially approved goals, concern for loved ones, habits and obligations &mdash; all appear to be better motivators than gaining pleasure, which we mostly seem to save for the little bit of free time left over. And to me, this is quite right and appropriate. I like pleasure, sure.&nbsp;<strong>I like joy. But that&rsquo;s not what I&rsquo;m after.</strong>&nbsp;It&rsquo;s a side effect, I hope, of the things I really care about. I&rsquo;d guess this is true of you too.</p>

<p>If maximizing pleasure is central to living well and improving the world, we&rsquo;re going about it entirely the wrong way. Do you really want to maximize pleasure? I doubt it. Me, I&rsquo;d rather write some good philosophy and raise my kids.</p>

<p><em>ETA, Nov 17:</em></p>

<p>In audience discussion and in social media, several people have pointed out although I start by talking about a wide range of emotional states (tranquility, delight, having good feelings about your life situation), in the second half I focus exclusively on pleasure. The case of pleasure is easiest to discuss, because the more complex emotional states have more representational or world-involving components. On a proper hedonic view, the value of those more complex states, however, rests exclusively on the emotional valence or at most on the emotional valence plus possibly-false representational content -- on, for example, whether you have the&nbsp;<em>feeling</em>&nbsp;that life is going well, rather than on whether it&#39;s really going well. All the same observations apply: We do and should care about whether our lives are actually going well, much more than we care about whether we have the emotional feeling of its going well.</p>
]]></data></Content><Content content_id="42" type="IMAGE"><title>Graphics Assignment 2</title><user_name>TheGreatDamien</user_name><profile_pic>uploads/picture/5e54017f53f57.jpg</profile_pic><f_name>Damien</f_name><l_name>Gerard</l_name><date>2020-04-25</date><data>content_image/5ea45213e0e63.png</data></Content><Content content_id="41" type="IMAGE"><title>Lonely  man</title><user_name>TheGreatDamien</user_name><profile_pic>uploads/picture/5e54017f53f57.jpg</profile_pic><f_name>Damien</f_name><l_name>Gerard</l_name><date>2020-04-24</date><data>content_image/5ea29e31614dc.jpg</data></Content><Content content_id="26" type="IMAGE"><title>Bridge</title><user_name>TheGreatDamien</user_name><profile_pic>uploads/picture/5e54017f53f57.jpg</profile_pic><f_name>Damien</f_name><l_name>Gerard</l_name><date>2020-01-01</date><data>content_image/5e0cf5f3ac625.jpg</data></Content><Content content_id="7" type="IMAGE"><title>Dark Sky</title><user_name>TheGreatDamien</user_name><profile_pic>uploads/picture/5e54017f53f57.jpg</profile_pic><f_name>Damien</f_name><l_name>Gerard</l_name><date>2019-11-19</date><data>content_image/5dd3581d4bd2b.jpg</data></Content><Content content_id="6" type="IMAGE"><title>minions</title><user_name>TheGreatDamien</user_name><profile_pic>uploads/picture/5e54017f53f57.jpg</profile_pic><f_name>Damien</f_name><l_name>Gerard</l_name><date>2019-11-19</date><data>content_image/5dd354743694d.jpg</data></Content><Content content_id="36" type="VIDEO"><title>Naruto vs Third Raikage</title><user_name>TheGreatDamien</user_name><profile_pic>uploads/picture/5e54017f53f57.jpg</profile_pic><f_name>Damien</f_name><l_name>Gerard</l_name><date>2020-01-09</date><data>content_video/thumbnails/5e171037ae934.jpg</data></Content><Content content_id="24" type="VIDEO"><title>CAT STEVENS - Wild World</title><user_name>TheGreatDamien</user_name><profile_pic>uploads/picture/5e54017f53f57.jpg</profile_pic><f_name>Damien</f_name><l_name>Gerard</l_name><date>2020-01-01</date><data>content_video/thumbnails/5e0cf1bf3deb5.jpg</data></Content><Content content_id="17" type="VIDEO"><title>Naruto vs Pain Full fight</title><user_name>TheGreatDamien</user_name><profile_pic>uploads/picture/5e54017f53f57.jpg</profile_pic><f_name>Damien</f_name><l_name>Gerard</l_name><date>2019-11-21</date><data>content_video/thumbnails/5dd6cb7069a20.jpg</data></Content><Content content_id="8" type="VIDEO"><title> Naruto vs Sasuke Full Fight</title><user_name>TheGreatDamien</user_name><profile_pic>uploads/picture/5e54017f53f57.jpg</profile_pic><f_name>Damien</f_name><l_name>Gerard</l_name><date>2019-11-19</date><data>content_video/thumbnails/5dd3842972e60.jpg</data></Content><Content content_id="3" type="VIDEO"><title>Cat Stevens - The wind</title><user_name>TheGreatDamien</user_name><profile_pic>uploads/picture/5e54017f53f57.jpg</profile_pic><f_name>Damien</f_name><l_name>Gerard</l_name><date>2019-11-18</date><data>content_video/thumbnails/5dd2ed99df22d.jpg</data></Content><Content content_id="37" type="QUESTION"><title> What is the best question and answer platform? Why?</title><user_name>TheGreatDamien</user_name><profile_pic>uploads/picture/5e54017f53f57.jpg</profile_pic><f_name>Damien</f_name><l_name>Gerard</l_name><date>2020-01-09</date><data>As far as I'm concerned Quora is the best one for me but I would like to confirm or deny. Are there any other platform with that level of quality.</data></Content></Contents>
